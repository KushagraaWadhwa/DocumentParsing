{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (4.36.2)\n",
      "Requirement already satisfied: pandas in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (from requests->transformers) (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SentencePiece in /Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages (0.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NATIVE QUESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q&A pairs have been saved to native_qa/native_qa_combined.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def save_to_csv(qa_pairs, csv_file):\n",
    "    df = pd.DataFrame(qa_pairs, columns=['question', 'response'])\n",
    "    if os.path.exists(csv_file):\n",
    "        df.to_csv(csv_file, mode='a', index=False, header=False)\n",
    "        print(f\"Q&A pairs have been appended to {csv_file}\")\n",
    "    else:\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"New CSV file {csv_file} has been created with Q&A pairs\")\n",
    "\n",
    "def save_to_text(qa_pairs, text_file):\n",
    "    with open(text_file, 'a', encoding='utf-8') as file:\n",
    "        for question, answer in qa_pairs:\n",
    "            file.write(f\"Question: {question}\\n\")\n",
    "            file.write(f\"Answer: {answer}\\n\\n\")\n",
    "    print(f\"Q&A pairs have been saved to {text_file}\")\n",
    "\n",
    "def generate_qa(json_file, document_name):\n",
    "    if not os.path.exists(json_file) or os.path.getsize(json_file) == 0:\n",
    "        raise ValueError(f\"The file {json_file} does not exist or is empty.\")\n",
    "    \n",
    "    with open(json_file, 'r') as file:\n",
    "        try:\n",
    "            data = json.load(file)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Error decoding JSON from file {json_file}: {e}\")\n",
    "    \n",
    "    questions_answers = []\n",
    "      \n",
    "    for key, value in data.items():\n",
    "        question = re.sub(r'^\\d+(\\.\\d+)*\\.\\s*', '', key).strip()\n",
    "        question = f\"What is the {question} in {document_name}?\"\n",
    "        answer = re.sub(r'\\\\u[0-9a-fA-F]{4}', \"\", value)\n",
    "        answer = re.sub(r'^[^a-zA-Z0-9\\s]+', '', answer, flags=re.MULTILINE)\n",
    "            \n",
    "        questions_answers.append((question, answer))\n",
    "    \n",
    "    return questions_answers\n",
    "\n",
    "json_file = '/Users/kushagrawadhwa/Desktop/PDF parser/llama_parser/output_policy2.json'\n",
    "document_name = 'the Handbook'\n",
    "csv_file = 'native_qa/native_qa_pairs2.0.csv'\n",
    "text_file = 'native_qa/native_qa_combined.txt'\n",
    "\n",
    "try:\n",
    "    qa_pairs = generate_qa(json_file, document_name)\n",
    "    # save_to_csv(qa_pairs, csv_file)\n",
    "    save_to_text(qa_pairs, text_file)\n",
    "except ValueError as e:\n",
    "    print(e)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-5 QUESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "/Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:1564: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q&A pairs have been saved to t-5_qa/t-5_qa_combined.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "t5_model_name = \"mrm8488/t5-base-finetuned-question-generation-ap\"\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(t5_model_name)\n",
    "model = AutoModelWithLMHead.from_pretrained(t5_model_name)\n",
    "\n",
    "def generate_question(answer, context):\n",
    "    input_text = f\"answer: {answer} context: {context}\"\n",
    "    input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids, max_length=64)\n",
    "    question = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    if question.startswith(\"question: \"):\n",
    "        question = question[len(\"question: \"):]\n",
    "    return question\n",
    "\n",
    "\n",
    "def process_json_file(file_path, document_name):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    qa_pairs = []\n",
    "    for heading, content in data.items():\n",
    "        context = str(content)\n",
    "        answer = heading  \n",
    "        generated_question = generate_question(answer, context) \n",
    "        qa_pairs.append((generated_question, context))\n",
    "    return qa_pairs\n",
    "\n",
    "def save_to_csv(qa_pairs, csv_file):\n",
    "    df = pd.DataFrame(qa_pairs, columns=['question', 'response'])\n",
    "    if os.path.exists(csv_file):\n",
    "        df.to_csv(csv_file, mode='a', index=False, header=False)\n",
    "        print(f\"Q&A pairs have been appended to {csv_file}\")\n",
    "    else:\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"New CSV file {csv_file} has been created with Q&A pairs\")\n",
    "\n",
    "def save_to_text(qa_pairs, text_file):\n",
    "    with open(text_file, 'a', encoding='utf-8') as file:\n",
    "        for question, answer in qa_pairs:\n",
    "            file.write(f\"Question: {question}\\n\")\n",
    "            file.write(f\"Answer: {answer}\\n\\n\")\n",
    "    print(f\"Q&A pairs have been saved to {text_file}\")\n",
    "    \n",
    "file_path = '/Users/kushagrawadhwa/Desktop/PDF parser/llama_parser/output_handbook5_wo_inst.json'\n",
    "document_name = 'the Internal Mobility Policy'\n",
    "csv_file = 't-5_qa/t-5_qa_pairs.csv'\n",
    "text_file = 't-5_qa/t-5_qa_combined.txt'\n",
    "\n",
    "\n",
    "try:\n",
    "    qa_pairs = process_json_file(file_path, document_name)\n",
    "    # save_to_csv(qa_pairs, csv_file)\n",
    "    save_to_text(qa_pairs, text_file)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "/Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:1564: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "/Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/kushagrawadhwa/Desktop/PDF parser/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was the estimated cost of the Taj Mahal complex in 1653?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "t5_model_name = \"mrm8488/t5-base-finetuned-question-generation-ap\"\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(t5_model_name)\n",
    "model = AutoModelWithLMHead.from_pretrained(t5_model_name)\n",
    "\n",
    "text = 'Construction of the mausoleum was completed in 1648, but work continued on other phases of the project for another five years. The first ceremony held at the mausoleum was an observance by Shah Jahan, on 6 February 1643, of the 12th anniversary of the death of Mumtaz Mahal. The Taj Mahal complex is believed to have been completed in its entirety in 1653 at a cost estimated at the time to be around ₹5 million, which in 2023 would be approximately ₹35 billion (US$77.8 million).'\n",
    "\n",
    "def generate_question(text):\n",
    "    input_text = f\"Text: {text}\"\n",
    "    input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids, max_length=64)\n",
    "    question = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    if question.startswith(\"question: \"):\n",
    "        question = question[len(\"question: \"):]\n",
    "        print(question)\n",
    "    # return question\n",
    "\n",
    "try:\n",
    "    generate_question(text)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT QUESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "model_name = \"distilbert/distilbert-base-uncased\"\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate_question(context, answer):\n",
    "    inputs = tokenizer.encode_plus(answer, context, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "    outputs = model(**inputs)\n",
    "    start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "    start_index = torch.argmax(start_scores)\n",
    "    end_index = torch.argmax(end_scores)\n",
    "    question = tokenizer.decode(input_ids[start_index:end_index+1])\n",
    "\n",
    "    return question\n",
    "\n",
    "def process_json_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    qa_pairs = []\n",
    "    for heading, content in data.items():\n",
    "        context = str(content)\n",
    "        answer = heading  \n",
    "        generated_question = generate_question(context, answer)\n",
    "        qa_pairs.append((generated_question, context))\n",
    "    return qa_pairs\n",
    "\n",
    "def save_to_csv(qa_pairs, csv_file):\n",
    "    df = pd.DataFrame(qa_pairs, columns=['question', 'response'])\n",
    "    if os.path.exists(csv_file):\n",
    "        df.to_csv(csv_file, mode='a', index=False, header=False)\n",
    "        print(f\"Q&A pairs have been appended to {csv_file}\")\n",
    "    else:\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"New CSV file {csv_file} has been created with Q&A pairs\")\n",
    "\n",
    "file_path = '/Users/kushagrawadhwa/Desktop/PDF parser/llama_parser/output_policy1.json'\n",
    "csv_file = 'bert_qa/bert_qa_pairs.csv'\n",
    "\n",
    "try:\n",
    "    qa_pairs = process_json_file(file_path)\n",
    "    save_to_csv(qa_pairs, csv_file)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess csv files\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"/Users/kushagrawadhwa/Desktop/PDF parser/Q|A Pairs/native_qa/native_qa_pairs2.0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the Internal Mobility Guidelines in th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the 'Live Your Potential' - Internal M...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the Purpose in the Handboook?</td>\n",
       "      <td>The purpose of these guidelines is to ensure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the Scope in the Handboook?</td>\n",
       "      <td>These guidelines apply to all full-time employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the Employee Eligibility in the Handbo...</td>\n",
       "      <td>In order to be eligible for a movement to anot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>What is the Workplace Behavior in the Handboook?</td>\n",
       "      <td>Employees are expected to maintain a positive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>What is the Confidentiality in the Handboook?</td>\n",
       "      <td>All employees must maintain the confidentialit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>What is the Attendance and Punctuality in the ...</td>\n",
       "      <td>Employees are expected to arrive on time for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>What is the Communication in the Handboook?</td>\n",
       "      <td>Effective communication is key to the success ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>What is the Compliance in the Handboook?</td>\n",
       "      <td>All employees must comply with local laws and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>893 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    What is the Internal Mobility Guidelines in th...   \n",
       "1    What is the 'Live Your Potential' - Internal M...   \n",
       "2                What is the Purpose in the Handboook?   \n",
       "3                  What is the Scope in the Handboook?   \n",
       "4    What is the Employee Eligibility in the Handbo...   \n",
       "..                                                 ...   \n",
       "888   What is the Workplace Behavior in the Handboook?   \n",
       "889      What is the Confidentiality in the Handboook?   \n",
       "890  What is the Attendance and Punctuality in the ...   \n",
       "891        What is the Communication in the Handboook?   \n",
       "892           What is the Compliance in the Handboook?   \n",
       "\n",
       "                                              response  \n",
       "0                                                  NaN  \n",
       "1                                                  NaN  \n",
       "2    The purpose of these guidelines is to ensure t...  \n",
       "3    These guidelines apply to all full-time employ...  \n",
       "4    In order to be eligible for a movement to anot...  \n",
       "..                                                 ...  \n",
       "888  Employees are expected to maintain a positive ...  \n",
       "889  All employees must maintain the confidentialit...  \n",
       "890  Employees are expected to arrive on time for t...  \n",
       "891  Effective communication is key to the success ...  \n",
       "892  All employees must comply with local laws and ...  \n",
       "\n",
       "[893 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question      0\n",
       "response    130\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df_new.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('native_qa/native_qa_pairs2.0_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the Purpose in the Handboook?</td>\n",
       "      <td>The purpose of these guidelines is to ensure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the Scope in the Handboook?</td>\n",
       "      <td>These guidelines apply to all full-time employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the Employee Eligibility in the Handbo...</td>\n",
       "      <td>In order to be eligible for a movement to anot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the Process &amp; Approvals in the Handboook?</td>\n",
       "      <td>An email announcing the available open positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the Tech Stack in the Handboook?</td>\n",
       "      <td>Details about the technology stack used within...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>What is the Workplace Behavior in the Handboook?</td>\n",
       "      <td>Employees are expected to maintain a positive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>What is the Confidentiality in the Handboook?</td>\n",
       "      <td>All employees must maintain the confidentialit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>What is the Attendance and Punctuality in the ...</td>\n",
       "      <td>Employees are expected to arrive on time for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>What is the Communication in the Handboook?</td>\n",
       "      <td>Effective communication is key to the success ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>What is the Compliance in the Handboook?</td>\n",
       "      <td>All employees must comply with local laws and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "2                What is the Purpose in the Handboook?   \n",
       "3                  What is the Scope in the Handboook?   \n",
       "4    What is the Employee Eligibility in the Handbo...   \n",
       "5    What is the Process & Approvals in the Handboook?   \n",
       "7             What is the Tech Stack in the Handboook?   \n",
       "..                                                 ...   \n",
       "888   What is the Workplace Behavior in the Handboook?   \n",
       "889      What is the Confidentiality in the Handboook?   \n",
       "890  What is the Attendance and Punctuality in the ...   \n",
       "891        What is the Communication in the Handboook?   \n",
       "892           What is the Compliance in the Handboook?   \n",
       "\n",
       "                                              response  \n",
       "2    The purpose of these guidelines is to ensure t...  \n",
       "3    These guidelines apply to all full-time employ...  \n",
       "4    In order to be eligible for a movement to anot...  \n",
       "5    An email announcing the available open positio...  \n",
       "7    Details about the technology stack used within...  \n",
       "..                                                 ...  \n",
       "888  Employees are expected to maintain a positive ...  \n",
       "889  All employees must maintain the confidentialit...  \n",
       "890  Employees are expected to arrive on time for t...  \n",
       "891  Effective communication is key to the success ...  \n",
       "892  All employees must comply with local laws and ...  \n",
       "\n",
       "[689 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
